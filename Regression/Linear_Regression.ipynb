{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7413f658",
   "metadata": {},
   "source": [
    "#Creating Dta set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82bff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing dataset created!\n",
      "   square_footage  num_bedrooms  distance_to_city    house_price\n",
      "0     2248.357077             4          9.491474  274017.935657\n",
      "1     1930.867849             1          6.491259  198063.314927\n",
      "2     2323.844269             3          7.890856  236893.676654\n",
      "3     2761.514928             5          7.950681  347773.437843\n",
      "4     1882.923313             3          8.969839  198708.257146\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "# More realistic features\n",
    "square_footage = np.random.normal(2000, 500, num_samples)\n",
    "num_bedrooms = np.random.randint(1, 6, num_samples)\n",
    "distance_to_city = np.random.normal(10, 4, num_samples)\n",
    "\n",
    "# Realistic target: house price\n",
    "# Price = 100*sqft + 20000*bedrooms - 5000*distance + noise\n",
    "price = (100 * square_footage + \n",
    "         20000 * num_bedrooms - \n",
    "         5000 * distance_to_city + \n",
    "         np.random.normal(0, 25000, num_samples))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'square_footage': square_footage,\n",
    "    'num_bedrooms': num_bedrooms,\n",
    "    'distance_to_city': distance_to_city,\n",
    "    'house_price': price\n",
    "})\n",
    "\n",
    "df.to_csv('data.csv', index=False)\n",
    "print(\"Housing dataset created!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbe0f2",
   "metadata": {},
   "source": [
    "#Import Library and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c13c372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc81dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "x = df.iloc[:, :3].values  # First 3 columns as input features\n",
    "y = df.iloc[:, 3].values.reshape(-1, 1)  # 4th column as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc17360",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f0f6b",
   "metadata": {},
   "source": [
    "#Convert datas to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f6d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "x_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "x_test  = torch.tensor(X_test,  dtype=torch.float32).to(device)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test  = torch.tensor(y_test,  dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303765b1",
   "metadata": {},
   "source": [
    "#Dataset Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69436436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for regression.\n",
    "    Inputs and targets are already tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5caa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomDataset(x_train, y_train)\n",
    "testing_data = CustomDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc4c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_data, batch_size = 32 , shuffle=True , pin_memory= True)\n",
    "\n",
    "test_loader = DataLoader(testing_data, batch_size = 32 , shuffle=False, pin_memory= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d11a8",
   "metadata": {},
   "source": [
    "#Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336fbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully connected neural network for regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 1)  # Single output ‚Üí regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d28b5c",
   "metadata": {},
   "source": [
    "#Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a493d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct input dimension (number of features)\n",
    "#input_dim = x_train.shape[1]\n",
    "\n",
    "# Initialize model\n",
    "model = MyNN(x_train.shape[1])\n",
    "\n",
    "# Regression loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer (Adam is best for regression)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training settings\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8546aaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] | Train MSE: 0.500086\n",
      "Epoch [2/100] | Train MSE: 0.193165\n",
      "Epoch [3/100] | Train MSE: 0.181105\n",
      "Epoch [4/100] | Train MSE: 0.180940\n",
      "Epoch [5/100] | Train MSE: 0.169154\n",
      "Epoch [6/100] | Train MSE: 0.172827\n",
      "Epoch [7/100] | Train MSE: 0.166920\n",
      "Epoch [8/100] | Train MSE: 0.156167\n",
      "Epoch [9/100] | Train MSE: 0.156578\n",
      "Epoch [10/100] | Train MSE: 0.157328\n",
      "Epoch [11/100] | Train MSE: 0.162078\n",
      "Epoch [12/100] | Train MSE: 0.155469\n",
      "Epoch [13/100] | Train MSE: 0.151118\n",
      "Epoch [14/100] | Train MSE: 0.149792\n",
      "Epoch [15/100] | Train MSE: 0.163074\n",
      "Epoch [16/100] | Train MSE: 0.150848\n",
      "Epoch [17/100] | Train MSE: 0.150735\n",
      "Epoch [18/100] | Train MSE: 0.164481\n",
      "Epoch [19/100] | Train MSE: 0.155820\n",
      "Epoch [20/100] | Train MSE: 0.152044\n",
      "Epoch [21/100] | Train MSE: 0.151851\n",
      "Epoch [22/100] | Train MSE: 0.155951\n",
      "Epoch [23/100] | Train MSE: 0.154433\n",
      "Epoch [24/100] | Train MSE: 0.154482\n",
      "Epoch [25/100] | Train MSE: 0.154917\n",
      "Epoch [26/100] | Train MSE: 0.143555\n",
      "Epoch [27/100] | Train MSE: 0.148001\n",
      "Epoch [28/100] | Train MSE: 0.156478\n",
      "Epoch [29/100] | Train MSE: 0.153642\n",
      "Epoch [30/100] | Train MSE: 0.142784\n",
      "Epoch [31/100] | Train MSE: 0.150016\n",
      "Epoch [32/100] | Train MSE: 0.151094\n",
      "Epoch [33/100] | Train MSE: 0.155084\n",
      "Epoch [34/100] | Train MSE: 0.148100\n",
      "Epoch [35/100] | Train MSE: 0.152191\n",
      "Epoch [36/100] | Train MSE: 0.158763\n",
      "Epoch [37/100] | Train MSE: 0.149590\n",
      "Epoch [38/100] | Train MSE: 0.150153\n",
      "Epoch [39/100] | Train MSE: 0.149859\n",
      "Epoch [40/100] | Train MSE: 0.150562\n",
      "Epoch [41/100] | Train MSE: 0.146218\n",
      "Epoch [42/100] | Train MSE: 0.145955\n",
      "Epoch [43/100] | Train MSE: 0.143194\n",
      "Epoch [44/100] | Train MSE: 0.150591\n",
      "Epoch [45/100] | Train MSE: 0.149777\n",
      "Epoch [46/100] | Train MSE: 0.146469\n",
      "Epoch [47/100] | Train MSE: 0.143621\n",
      "Epoch [48/100] | Train MSE: 0.152220\n",
      "Epoch [49/100] | Train MSE: 0.138105\n",
      "Epoch [50/100] | Train MSE: 0.147677\n",
      "Epoch [51/100] | Train MSE: 0.147610\n",
      "Epoch [52/100] | Train MSE: 0.148622\n",
      "Epoch [53/100] | Train MSE: 0.151653\n",
      "Epoch [54/100] | Train MSE: 0.150618\n",
      "Epoch [55/100] | Train MSE: 0.142481\n",
      "Epoch [56/100] | Train MSE: 0.150568\n",
      "Epoch [57/100] | Train MSE: 0.155418\n",
      "Epoch [58/100] | Train MSE: 0.150240\n",
      "Epoch [59/100] | Train MSE: 0.146623\n",
      "Epoch [60/100] | Train MSE: 0.150085\n",
      "Epoch [61/100] | Train MSE: 0.141317\n",
      "Epoch [62/100] | Train MSE: 0.143850\n",
      "Epoch [63/100] | Train MSE: 0.143430\n",
      "Epoch [64/100] | Train MSE: 0.145080\n",
      "Epoch [65/100] | Train MSE: 0.142190\n",
      "Epoch [66/100] | Train MSE: 0.146744\n",
      "Epoch [67/100] | Train MSE: 0.153286\n",
      "Epoch [68/100] | Train MSE: 0.148884\n",
      "Epoch [69/100] | Train MSE: 0.145054\n",
      "Epoch [70/100] | Train MSE: 0.137910\n",
      "Epoch [71/100] | Train MSE: 0.140458\n",
      "Epoch [72/100] | Train MSE: 0.147757\n",
      "Epoch [73/100] | Train MSE: 0.150402\n",
      "Epoch [74/100] | Train MSE: 0.145072\n",
      "Epoch [75/100] | Train MSE: 0.140823\n",
      "Epoch [76/100] | Train MSE: 0.141290\n",
      "Epoch [77/100] | Train MSE: 0.141091\n",
      "Epoch [78/100] | Train MSE: 0.154154\n",
      "Epoch [79/100] | Train MSE: 0.144386\n",
      "Epoch [80/100] | Train MSE: 0.146007\n",
      "Epoch [81/100] | Train MSE: 0.145333\n",
      "Epoch [82/100] | Train MSE: 0.143719\n",
      "Epoch [83/100] | Train MSE: 0.142869\n",
      "Epoch [84/100] | Train MSE: 0.145433\n",
      "Epoch [85/100] | Train MSE: 0.139916\n",
      "Epoch [86/100] | Train MSE: 0.140639\n",
      "Epoch [87/100] | Train MSE: 0.143952\n",
      "Epoch [88/100] | Train MSE: 0.142503\n",
      "Epoch [89/100] | Train MSE: 0.141735\n",
      "Epoch [90/100] | Train MSE: 0.145676\n",
      "Epoch [91/100] | Train MSE: 0.143487\n",
      "Epoch [92/100] | Train MSE: 0.146140\n",
      "Epoch [93/100] | Train MSE: 0.143332\n",
      "Epoch [94/100] | Train MSE: 0.143853\n",
      "Epoch [95/100] | Train MSE: 0.148253\n",
      "Epoch [96/100] | Train MSE: 0.142308\n",
      "Epoch [97/100] | Train MSE: 0.146745\n",
      "Epoch [98/100] | Train MSE: 0.144968\n",
      "Epoch [99/100] | Train MSE: 0.138492\n",
      "Epoch [100/100] | Train MSE: 0.135003\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # Loss computation\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Train MSE: {avg_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb8c223",
   "metadata": {},
   "source": [
    "#Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f8370d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "MSE  : 0.153577\n",
      "RMSE : 0.391890\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(x_test)\n",
    "    test_mse = criterion(test_predictions, y_test)\n",
    "    test_rmse = torch.sqrt(test_mse)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"MSE  : {test_mse.item():.6f}\")\n",
    "print(f\"RMSE : {test_rmse.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e5dd8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R¬≤ Score (test set): 0.8262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get predictions (scaled)\n",
    "    y_pred_scaled = model(x_test)\n",
    "\n",
    "# Move tensors to CPU and convert to NumPy\n",
    "y_pred_scaled = y_pred_scaled.cpu().numpy()\n",
    "y_test_scaled = y_test.cpu().numpy()\n",
    "\n",
    "# üîÅ Inverse transform to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_true = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "# üìä Compute R¬≤ score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"R¬≤ Score (test set): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31e7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
